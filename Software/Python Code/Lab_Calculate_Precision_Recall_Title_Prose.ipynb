{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code calculates precision and recall scores of title/prose detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_files(pattern, path):\n",
    "    \"\"\"\n",
    "    Walks the path recursively and returns a list of files\n",
    "    whose filenames match the pattern passed.\n",
    "    \n",
    "    Input: pattern, path\n",
    "    Output: list of file names\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if fnmatch.fnmatch(name, pattern):\n",
    "                result.append(os.path.join(root, name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "semantic_header_files = find_files('dom_ind.headers', r'C:/UsablePrivacyPolicy/Data/Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_header_files = find_files('gold.headers', r'C:/UsablePrivacyPolicy/Data/Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_final_folder(absolute_path):\n",
    "    \"\"\"\n",
    "    Extracts the string which appears between the final folder separator\n",
    "    and the pre final folder separator\n",
    "    \n",
    "    Ex - Input = C:\\\\UsablePrivacyPolicy\\\\Data\\\\OtherSites\\\\activision.com\\\\activision.txt\n",
    "    Returns activision.com\n",
    "    \"\"\"\n",
    "    substring = absolute_path[:absolute_path.rfind('\\\\')]\n",
    "    return substring[substring.rfind('\\\\')+1 :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_headers(absolute_path):\n",
    "    \"\"\"\n",
    "    returns all the lines present in the file passed as a list\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    with open (absolute_path) as f:\n",
    "        headers = f.readlines()\n",
    "    \n",
    "    \n",
    "    headers_return = []\n",
    "    for each_line in headers:\n",
    "        each_line = each_line.strip().lower()\n",
    "        \n",
    "        headers_return.append(''.join(e for e in each_line if e.isalnum()))\n",
    "    \n",
    "    return set(headers_return)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_header_dict(header_file_list):\n",
    "    \"\"\"\n",
    "    returns a dictionary with the following pattern\n",
    "    {final_folder_name:[Header1,Header2]}\n",
    "    \"\"\"\n",
    "    dict_headers = {}\n",
    "    for each_file in header_file_list:\n",
    "        final_folder_name = extract_final_folder(each_file)\n",
    "        list_headers = extract_headers(each_file)\n",
    "        dict_headers[final_folder_name] = list_headers\n",
    "    \n",
    "    return dict_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_semantic_headers = create_header_dict(semantic_header_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_master_headers = create_header_dict(master_header_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(len(dict_semantic_headers) == len(dict_master_headers)), \"Lengths don't match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to precision and recall part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_file = open('results_headers_markers.html','w')\n",
    "\n",
    "file_contents = \"\"\"<html>\n",
    "<head><title>Header Evaluation Results</title></head>\n",
    "<body><table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <th>Website</th>\n",
    "    <th>Precision</th> \n",
    "    <th>Recall</th>\n",
    "    <th>F1</th>\n",
    "  </tr>\"\"\"\n",
    "\n",
    "close_html = \"\"\"</body></html>\"\"\"\n",
    "\n",
    "#f.write(message)\n",
    "#f.close()\n",
    "\n",
    "#webbrowser.open_new_tab('helloworld.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_precision = 0\n",
    "total_recall = 0\n",
    "global_correct_headers = 0\n",
    "global_predicted_headers = 0\n",
    "global_correct_predicted_headers = 0\n",
    "\n",
    "\n",
    "\n",
    "for website, master_header_list in dict_master_headers.items():\n",
    "    \n",
    "    # Get the corresponding semantic header\n",
    "    try:\n",
    "        semantic_header_list = dict_semantic_headers[website]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    #print(master_header_list)\n",
    "    #print(semantic_header_list)\n",
    "    \n",
    "    total_correct_headers = len(master_header_list)\n",
    "    total_predicted_headers = len(semantic_header_list)\n",
    "    total_correct_predicted_headers = 0\n",
    "    \n",
    "    for each_master_header in master_header_list:\n",
    "        for each_semantic_header in semantic_header_list:\n",
    "            if(each_master_header in each_semantic_header or each_semantic_header in each_master_header):\n",
    "                total_correct_predicted_headers += 1\n",
    "                #print(each_master_header)\n",
    "                break\n",
    "    \n",
    "    if(total_correct_predicted_headers > total_predicted_headers):\n",
    "        total_correct_predicted_headers = total_predicted_headers\n",
    "    \n",
    "    try:\n",
    "        recall = total_correct_predicted_headers / total_correct_headers\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "        \n",
    "    try:\n",
    "        precision = total_correct_predicted_headers / total_predicted_headers\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "        \n",
    "    #total_precision += precision\n",
    "    try:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0\n",
    "        \n",
    "    global_correct_headers += total_correct_headers\n",
    "    global_predicted_headers += total_predicted_headers\n",
    "    global_correct_predicted_headers += total_correct_predicted_headers\n",
    "    \n",
    "    file_contents = file_contents + \"<tr><td>\" + website + \"</td>\" + \"<td>\" + '{0:.2f}'.format(precision) + \"</td>\"\n",
    "    file_contents = file_contents + \"<td>\" + '{0:.2f}'.format(recall) + \"</td>\"\n",
    "    file_contents = file_contents + \"<td>\" + '{0:.2f}'.format(f1) + \"</td></tr>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    total_precision = global_correct_predicted_headers / global_predicted_headers\n",
    "except ZeroDivisionError:\n",
    "        precision = 0\n",
    "\n",
    "try:\n",
    "    total_recall = global_correct_predicted_headers / global_correct_headers\n",
    "except ZeroDivisionError:\n",
    "        precision = 0\n",
    "\n",
    "total_f1 = 2 * total_precision * total_recall / (total_precision + total_recall)\n",
    "print(global_correct_headers)\n",
    "print(global_correct_predicted_headers)\n",
    "print(global_predicted_headers)\n",
    "file_contents = file_contents + \"<tr><td>\" + \"Total\" + \"</td>\" + \"<td>\" + '{0:.4f}'.format(total_precision) + \"</td>\"\n",
    "file_contents = file_contents + \"<td>\" + '{0:.4f}'.format(total_recall) + \"</td>\"\n",
    "file_contents = file_contents + \"<td>\" + '{0:.4f}'.format(total_f1) + \"</td></tr>\"\n",
    "\n",
    "file_contents = file_contents + \"</table>\" + close_html\n",
    "\n",
    "results_file.write(file_contents)\n",
    "results_file.close()\n",
    "\n",
    "webbrowser.open_new_tab('results_headers_markers.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
